{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models.resnet import ResNet\n",
    "from models.unet import UNet\n",
    "from models.skip import skip\n",
    "from models import get_net\n",
    "import torch\n",
    "import torch.optim\n",
    "# from skimage.measure import compare_psnr\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from util.common_utils import * \n",
    "from util.loss import total_variation\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "PLOT = True\n",
    "imsize=-1\n",
    "dim_div_by = 64\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# video_file = './data/RAW.avi'\n",
    "\n",
    "# img_np_list = []\n",
    "# img_gpu_list = []\n",
    "\n",
    "# cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "# while (cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret == True:\n",
    "#         img_np = frame[..., 0]\n",
    "#         img_np = np.expand_dims(img_np, 0)\n",
    "#         img_np = np.array(img_np, dtype=np.float32) / 255.0\n",
    "#         img_np_list.append(img_np)\n",
    "#         img_gpu_list.append(np_to_torch(img_np).type(dtype))\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# print(\"img_np shape: \", img_np_list[0].shape)\n",
    "\n",
    "# _ = plot_image_grid([img_np_list[0], img_np_list[-1]], factor=4, nrow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './data/building'\n",
    "# base_dir = './data/power_supply'\n",
    "img_dir = os.path.join(base_dir, \"images_fpn\")\n",
    "\n",
    "file_list = os.listdir(img_dir)\n",
    "file_list = sorted(file_list, key= lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "img_np_list = []\n",
    "img_gpu_list = []\n",
    "img_clean_list = []\n",
    "\n",
    "for f in file_list:\n",
    "    _, img_np = get_image(os.path.join(img_dir, f), imsize)\n",
    "    img_np = img_np[0:1, :, :] \n",
    "    img_np_list.append(img_np)\n",
    "    img_gpu_list.append(np_to_torch(img_np).type(dtype))\n",
    "\n",
    "print(\"img_np shape: \", img_np_list[0].shape)\n",
    "\n",
    "_ = plot_image_grid([img_np_list[0], img_np_list[-1]], factor=4, nrow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 1\n",
    "test_frac = 1 - train_frac\n",
    "\n",
    "num_train = int(len(img_np_list) * train_frac)\n",
    "train_index = np.random.choice(range(len(img_np_list)), num_train, replace=False)\n",
    "print(train_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_every=200\n",
    "figsize=5\n",
    "pad = 'reflection' # 'zero'\n",
    "INPUT = 'noise'\n",
    "input_depth = 32\n",
    "OPTIMIZER = 'adam'\n",
    "OPT_OVER =  'net'\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "\n",
    "LR = 1e-3\n",
    "num_iter = 15000\n",
    "iter_step = 1500\n",
    "\n",
    "reg_noise_std = 3e-5\n",
    "\n",
    "NET_TYPE = 'skip'\n",
    "net = get_net(input_depth, 'skip', pad, n_channels=1,\n",
    "              skip_n33d=128, \n",
    "              skip_n33u=128, \n",
    "              skip_n11=4, \n",
    "              num_scales=5,\n",
    "              upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "# Loss\n",
    "mse = torch.nn.MSELoss().type(dtype)\n",
    "#img_var = np_to_torch(img_np).type(dtype)\n",
    "\n",
    "net_input = get_noise(input_depth, INPUT, img_np.shape[1:]).type(dtype).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global i, last_net, net_input\n",
    "    \n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "    \n",
    "    out = net(net_input)\n",
    "\n",
    "    index = np.random.choice(train_index, size=1)[0]\n",
    "\n",
    "    target = img_np_list[index]\n",
    "    target_gpu = img_gpu_list[index]\n",
    "\n",
    "\n",
    "    if i <= iter_step * 1:\n",
    "        tv_step = np.random.randint(50, 60)\n",
    "    elif i <= iter_step * 2:\n",
    "        tv_step = np.random.randint(40, 50)\n",
    "    elif i <= iter_step * 3:\n",
    "        tv_step = np.random.randint(30, 40)\n",
    "    elif i <= iter_step * 4:\n",
    "        tv_step = np.random.randint(20, 30)\n",
    "    elif i <= iter_step * 5:\n",
    "        tv_step = np.random.randint(10, 20)\n",
    "    elif i <= iter_step * 6:\n",
    "        tv_step = np.random.randint(3, 10)\n",
    "    else:\n",
    "        tv_step = 1\n",
    "    \n",
    "    total_loss = total_variation(img_gpu_list[index] - out, reduction=\"sum\", step=tv_step) #+ 1e-1 * mse(fpn_target, out)\n",
    "    \n",
    "    total_loss.backward()\n",
    "\n",
    "    learned_noise = out.detach().cpu().numpy()[0]\n",
    "    out_clean = img_np_list[index] - out.detach().cpu().numpy()[0]\n",
    "    out_clean_norm = (out_clean-np.min(out_clean))/(np.max(out_clean)-np.min(out_clean))\n",
    "    psrn = peak_signal_noise_ratio(img_np_list[index], out_clean_norm) \n",
    "\n",
    "    print ('Iteration %05d    Loss %f PSNR %f' % (i, total_loss.item(), psrn),'\\r', end='')\n",
    "    \n",
    "    if  PLOT and i % show_every == 0:\n",
    "        plot_image_grid([np.clip(learned_noise, 0, 1), target, out_clean_norm], factor=figsize, nrow=3)\n",
    "\n",
    "    i += 1\n",
    "    return total_loss\n",
    "\n",
    "# Init globals \n",
    "last_net = None\n",
    "i = 0\n",
    "\n",
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "\n",
    "# Run\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "optimize(OPTIMIZER, p, closure, LR=LR, num_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closure():\n",
    "\n",
    "#     global i, last_net, net_input, index, num_iter\n",
    "    \n",
    "#     if reg_noise_std > 0:\n",
    "#         net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "    \n",
    "#     out = net(net_input)\n",
    "\n",
    "#     target = img_np_list[index]\n",
    "#     target_gpu = img_gpu_list[index]\n",
    "    \n",
    "#     #tv_step = np.random.randint(3, 10)\n",
    "#     tv_step = np.random.randint(5, 30)\n",
    "#     total_loss = total_variation(img_gpu_list[index] - out, reduction=\"sum\", step=1) + \\\n",
    "#                  total_variation(img_gpu_list[index] - out, reduction=\"sum\", step=tv_step)\n",
    "\n",
    "#     total_loss.backward()\n",
    "    \n",
    "#     learned_noise = out.detach().cpu().numpy()[0]\n",
    "#     out_clean = img_np_list[index] - out.detach().cpu().numpy()[0]\n",
    "#     out_clean_norm = (out_clean-np.min(out_clean))/(np.max(out_clean)-np.min(out_clean))\n",
    "#     psrn = peak_signal_noise_ratio(img_np_list[index], out_clean_norm) \n",
    "\n",
    "#     print ('Iteration %05d    Loss %f PSNR %f' % (i, total_loss.item(), psrn),'\\r', end='')\n",
    "    \n",
    "#     i += 1\n",
    "#     return total_loss\n",
    "\n",
    "\n",
    "# out_list = []\n",
    "\n",
    "# for index, img_np in enumerate(img_np_list):\n",
    "#     last_net = None\n",
    "#     i = 0\n",
    "#     num_iter = 5\n",
    "#     LR = 1e-4\n",
    "\n",
    "#     # Run\n",
    "#     p = get_params(OPT_OVER, net, net_input)\n",
    "#     optimize(OPTIMIZER, p, closure, LR=LR, num_iter=num_iter)\n",
    "\n",
    "#     out_np = torch_to_np(net(net_input))\n",
    "#     out_clean = img_np - out_np[0]\n",
    "#     out_clean_norm = (out_clean-np.min(out_clean))/(np.max(out_clean)-np.min(out_clean))\n",
    "#     out_list.append(out_clean_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_np = torch_to_np(net(net_input))\n",
    "\n",
    "out_list = []\n",
    "\n",
    "for img_np in img_np_list:\n",
    "    out_clean = img_np - out_np[0]\n",
    "    out_clean_norm = (out_clean-np.min(out_clean))/(np.max(out_clean)-np.min(out_clean))\n",
    "    out_list.append(out_clean_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width = img_np_list[0].shape[2]\n",
    "frame_height = img_np_list[0].shape[1]\n",
    " \n",
    "print(f\"Frame shape: {frame_width} x {frame_height}\")\n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "out = cv2.VideoWriter('out.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 5, (frame_width, frame_height), False)\n",
    " \n",
    "for index, out_img in enumerate(out_list):\n",
    "    # Write the frame into the file 'output.avi'\n",
    "    frame = out_img[0, ...] \n",
    "    frame = frame * 255\n",
    "    frame = np.array(frame, dtype=np.uint8)\n",
    "\n",
    "    # Display the resulting frame    \n",
    "    cv2.imshow('frame',frame)\n",
    " \n",
    "    # Press Q on keyboard to stop recording\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "      break\n",
    "    out.write(frame)\n",
    "    \n",
    "    cv2.imwrite(\"out-tv-dip-{}\".format(file_list[index]), frame)\n",
    "\n",
    "out.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('deep-image-prior')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "336dbf19670fe69df6c849624cd56b17c6cf8c8a65fd2e6b6b56f40fb3bf8b21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
